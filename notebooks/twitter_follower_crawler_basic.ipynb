{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User GET Endpoint Rate Limits: https://developer.twitter.com/en/docs/basics/rate-limits\n",
    "\n",
    "\"\"\"\n",
    "env:\n",
    "    TWITTER_CONSUMER_KEY:\n",
    "    TWITTER_CONSUMER_SECRET:\n",
    "    TWITTER_ACCESS_TOKEN:\n",
    "    TWITTER_ACCESS_TOKEN_SECRET:\n",
    "    \n",
    "get_user_interactions: \n",
    "    args:\n",
    "        twitter_usernames - A list of usernames for the twitter username. (could use id)\n",
    "    \n",
    "    returns: \n",
    "        interactions_count - list of tuples in the format (\"username\", count)\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tweepy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from decouple import config\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import csv\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_AUTH = tweepy.OAuthHandler(config('TWITTER_CONSUMER_KEY'),config('TWITTER_CONSUMER_SECRET'))\n",
    "\n",
    "TWITTER_AUTH.set_access_token(config('TWITTER_ACCESS_TOKEN'),config('TWITTER_ACCESS_TOKEN_SECRET'))\n",
    "\n",
    "TWITTER = tweepy.API(TWITTER_AUTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine current rate limit stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the limit before running the function, then check again after and compare. \n",
    "start_api_check = TWITTER.rate_limit_status()\n",
    "limits_alpha = json_normalize(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function performs search of user's interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_user_interactions(search):\n",
    "    twitter_user = TWITTER.get_user(search)\n",
    "    tweets = twitter_user.timeline(\n",
    "                count=200, # Tweepy limit. \n",
    "                exclude_replies=False,\n",
    "                include_rts=True,\n",
    "                tweet_mode='extended')\n",
    "    b = [ i.full_text for i in tweets ]\n",
    "    b = \" \".join(b)\n",
    "    b = b.lower()\n",
    "    b = b.replace(search, \"\")\n",
    "    interactions = re.findall(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)',b)\n",
    "    interactions_count = Counter(interactions).most_common(10)\n",
    "    return interactions_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_user_connections(search):\n",
    "    twitter_user = TWITTER.get_user(search)\n",
    "    tweets = twitter_user.timeline(\n",
    "                count=1000,\n",
    "                exclude_replies=False,\n",
    "                include_rts=True,\n",
    "                tweet_mode='extended')\n",
    "    b = [ i.full_text for i in tweets ]\n",
    "    b = \" \".join(b)\n",
    "    b = b.lower()\n",
    "    b = b.replace(search, \"\")\n",
    "    interactions = re.findall(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)',b)\n",
    "    interactions = \" \".join(interactions)\n",
    "    interactions_list.append(interactions)\n",
    "    index.append(search)\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"bwinterrose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 11.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('lambdaschool', 34),\n",
       " ('austen', 22),\n",
       " ('kaggle', 15),\n",
       " ('superhuman', 9),\n",
       " ('tommycollison', 8),\n",
       " ('paulg', 5),\n",
       " ('mwseibel', 5),\n",
       " ('arachnocapital2', 4),\n",
       " ('rasbt', 4),\n",
       " ('jason', 4)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "test_peeps = get_first_user_interactions(user)\n",
    "test_peeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch user's interactions and user's interactions' interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_interactions(username):\n",
    "    a = get_first_user_interactions(username)\n",
    "    an_interactions_list = []\n",
    "    an_index = []\n",
    "    get_first_user_connections(username)\n",
    "    for i in range(len(a)):\n",
    "        get_first_user_connections(a[i][0])\n",
    "    return (an_interactions_list, an_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-f92256e3847f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    963\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = interactions_list\n",
    "vectorizer = CountVectorizer(min_df=2)\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "display_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names(), index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "DG=nx.MultiGraph()\n",
    "\n",
    "#loop through index, then the columns to find non-zero connections.\n",
    "for i in display_df.index.values:\n",
    "    for j in display_df.columns:\n",
    "        if display_df[j].loc[i] >0 :\n",
    "            DG.add_edge(j,i,display_df[j].loc[i] )\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "fig = plt.figure(figsize=(8,8))\n",
    "nx.draw_kamada_kawai(DG,node_size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine API Impact of changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_api_check = TWITTER.rate_limit_status()\n",
    "limits_beta = json_normalize(end_api_check).T\n",
    "limits_beta.rename(columns = {0:'beta',}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sub_type</th>\n",
       "      <th>api_path</th>\n",
       "      <th>method</th>\n",
       "      <th>stat</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>resources</td>\n",
       "      <td>application</td>\n",
       "      <td>/application/rate_limit_status</td>\n",
       "      <td>rate_limit_status</td>\n",
       "      <td>remaining</td>\n",
       "      <td>163</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type     sub_type                        api_path             method  \\\n",
       "50  resources  application  /application/rate_limit_status  rate_limit_status   \n",
       "\n",
       "         stat alpha beta  delta  \n",
       "50  remaining   163  179   True  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the change of ALL API ENDPOINTS between limits, alpha (before run), and beta (after run.)\n",
    "limits_delta = limits_alpha.T.copy()\n",
    "limits_delta['beta'] = limits_beta['beta']\n",
    "limits_delta = limits_delta.reset_index(drop=False)\n",
    "limits_delta.rename(columns = {0:'alpha', 'index':'api_endpoint'}, inplace = True)\n",
    "limits_delta = limits_delta[['api_endpoint','alpha', 'beta']].assign(delta=limits_delta.alpha != limits_delta.beta)\n",
    "limits_delta['type'] = limits_delta.api_endpoint.str.split(pat = '.', n = 1, expand = True)[0]\n",
    "limits_delta['sub_type'] = limits_delta.api_endpoint.str.split(pat = '.', n = 2, expand = True)[1]\n",
    "limits_delta['api_path'] = limits_delta.api_endpoint.str.split(pat = '.', n = 2, expand = True)[2].str.rsplit(pat = '.', n = 1, expand = True)[0]\n",
    "limits_delta['method'] = limits_delta.api_path.str.rsplit(pat = '/', n = 1, expand = True)[1]\n",
    "limits_delta['stat'] = limits_delta.api_endpoint.str.rsplit(pat = '.', n = 1, expand = True)[1]\n",
    "limits_delta = limits_delta[['type', 'sub_type', 'api_path', 'method', 'stat', 'alpha', 'beta', 'delta']]\n",
    "\n",
    "# Display filtered df. \n",
    "limits_delta[(limits_delta['stat'].str.contains(\"reset\") == False) & (limits_delta['delta']==True)]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
